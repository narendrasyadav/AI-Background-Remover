{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "290327d4"
      },
      "source": [
        "## Explore different `rembg` models\n",
        "\n",
        "To potentially achieve more accurate background removal, especially for specific types of images, you can experiment with different models provided by the `rembg` library. The default model is `u2net`, which is a general-purpose model.\n",
        "\n",
        "Here are some commonly used models and their potential use cases:\n",
        "\n",
        "*   **`u2net` (default)**: A general-purpose model that works well for a wide variety of images.\n",
        "*   **`u2netp`**: A smaller version of `u2net`, which might be faster but potentially slightly less accurate.\n",
        "*   **`u2net_human_seg`**: Specifically trained for segmenting humans. This can be very accurate for photos of people.\n",
        "*   **`isnet-general-use`**: A newer general-purpose model that might perform better on certain images compared to `u2net`.\n",
        "*   **`isnet-anime`**: Trained specifically for anime-style images.\n",
        "*   **`sam` (Segment Anything Model)**: A very powerful, large model that can perform accurate segmentation. However, it typically requires more resources and might involve a different workflow or additional dependencies.\n",
        "\n",
        "You can see the full list of available models by running the following code in a cell:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "236f6e2e"
      },
      "source": [
        "In the next step, I will show you how to modify the code to select a different model for background removal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ba547c1"
      },
      "source": [
        "This code does the following:\n",
        "\n",
        "1.  **Installs Gradio**: The first cell installs the necessary library.\n",
        "2.  **Imports Libraries**: Imports `gradio`, `remove` and `new_session` from `rembg`, and `PIL` for image handling.\n",
        "3.  **`remove_background_gradio` Function**: This function takes a PIL Image and a model name as input, uses `rembg` to remove the background, and returns the processed PIL Image.\n",
        "4.  **Model Options**: It dynamically gets the available models from `rembg` to populate the dropdown.\n",
        "5.  **Gradio Interface**: It defines the Gradio interface with:\n",
        "    *   `fn`: The function to run (`remove_background_gradio`).\n",
        "    *   `inputs`: An image upload component and a dropdown for model selection.\n",
        "    *   `outputs`: An image display component for the result.\n",
        "    *   `title` and `description`: Text to display on the web interface.\n",
        "6.  **Launch**: `iface.launch()` starts the Gradio web server. Gradio will provide a public URL that you can click to access the interface in your browser.\n",
        "\n",
        "You can run these cells in Colab, and a link will appear in the output that you can click to use the background remover application in your web browser."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaa409f2",
        "outputId": "02a79f66-4e46-481e-8f21-af9e799d5e51"
      },
      "source": [
        "# While directly listing all models programmatically might be complex without inspecting rembg internals\n",
        "# or specific documentation functions, the common models used with rembg include:\n",
        "# 'u2net' (default)\n",
        "# 'u2netp' (a smaller version of u2net)\n",
        "# 'u2net_human_seg' (specifically trained for human segmentation)\n",
        "# 'isnet-general-use' (a newer general-purpose model)\n",
        "# 'isnet-anime' (specifically trained for anime style images)\n",
        "# 'sam' (Segment Anything Model - requires additional setup and understanding of its usage)\n",
        "\n",
        "# For the purpose of this exploration subtask, noting the commonly used models is sufficient.\n",
        "# The next step in the overall task will involve incorporating these into the Gradio interface.\n",
        "\n",
        "print(\"Commonly used rembg models:\")\n",
        "print(\"- 'u2net' (default)\")\n",
        "print(\"- 'u2netp' (smaller u2net)\")\n",
        "print(\"- 'u2net_human_seg' (human segmentation)\")\n",
        "print(\"- 'isnet-general-use' (general purpose)\")\n",
        "print(\"- 'isnet-anime' (anime images)\")\n",
        "print(\"- 'sam' (Segment Anything Model - advanced)\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Commonly used rembg models:\n",
            "- 'u2net' (default)\n",
            "- 'u2netp' (smaller u2net)\n",
            "- 'u2net_human_seg' (human segmentation)\n",
            "- 'isnet-general-use' (general purpose)\n",
            "- 'isnet-anime' (anime images)\n",
            "- 'sam' (Segment Anything Model - advanced)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2b39c1d"
      },
      "source": [
        "# Task\n",
        "Add manual background removal using mouse cursor on the processed image with an edit button option at the last in the Gradio UI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05afc148"
      },
      "source": [
        "## Modify gradio interface for annotation\n",
        "\n",
        "### Subtask:\n",
        "Update the `gr.Image` component in the Gradio interface to enable an annotation mode (e.g., drawing bounding boxes).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2f6921b"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to modify the `gr.Image` input component in the Gradio interface definition to make it interactive and enable drawing bounding boxes. I will add the `interactive=True` and `tool='boxes'` parameters to the input `gr.Image` component.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ca853b0"
      },
      "source": [
        ""
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "26dfd22e",
        "outputId": "e585c10c-d635-43da-ca9f-7ad3cdf6b0d7"
      },
      "source": [
        "import gradio as gr\n",
        "from rembg import remove, new_session\n",
        "from PIL import Image, ImageFilter\n",
        "import io\n",
        "import numpy as np\n",
        "\n",
        "# Available models for Gradio dropdown (already defined)\n",
        "try:\n",
        "    model_options = list(new_session.AVAILABLE_MODELS.keys())\n",
        "except AttributeError:\n",
        "    model_options = ['u2net', 'u2netp', 'u2net_human_seg', 'isnet-general-use', 'isnet-anime']\n",
        "\n",
        "\n",
        "# Function to remove background using rembg and optionally sharpen\n",
        "def remove_background_gradio(input_image, model_name='u2net', sharpen_output=False):\n",
        "    \"\"\"\n",
        "    Removes background from an image using the specified rembg model with alpha matting\n",
        "    and optionally applies a sharpening filter.\n",
        "    \"\"\"\n",
        "    if input_image is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        session = new_session(model_name)\n",
        "        img_byte_arr = io.BytesIO()\n",
        "        input_image.save(img_byte_arr, format='PNG') # Save as PNG to preserve transparency\n",
        "        img_byte_arr = img_byte_arr.getvalue()\n",
        "\n",
        "        output_bytes = remove(\n",
        "            img_byte_arr,\n",
        "            session=session,\n",
        "            alpha_matting=True,\n",
        "            alpha_matting_foreground_threshold=240,\n",
        "            alpha_matting_background_threshold=10,\n",
        "            alpha_matting_erode_size=10\n",
        "        )\n",
        "\n",
        "        processed_image = Image.open(io.BytesIO(output_bytes)).convert('RGBA')\n",
        "\n",
        "        # --- Conditional Sharpening Step ---\n",
        "        if sharpen_output:\n",
        "            # Split into RGB and Alpha channels\n",
        "            rgb_image = processed_image.convert('RGB')\n",
        "            alpha_channel = processed_image.getchannel('A')\n",
        "\n",
        "            # Apply sharpening filter to the RGB image\n",
        "            sharpened_rgb_image = rgb_image.filter(ImageFilter.SHARPEN)\n",
        "\n",
        "            # Recombine the sharpened RGB image with the original alpha channel\n",
        "            processed_image = Image.merge('RGBA', (sharpened_rgb_image.split() + (alpha_channel,)))\n",
        "            # --- End Conditional Sharpening Step ---\n",
        "\n",
        "\n",
        "        # Return the processed RGBA image (sharpened or not)\n",
        "        return processed_image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during background removal or sharpening: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Function to prepare image for download\n",
        "def prepare_image_for_download(image: Image.Image):\n",
        "    \"\"\"\n",
        "    Saves a PIL Image to a BytesIO object and returns its byte content for download.\n",
        "    \"\"\"\n",
        "    if image is None:\n",
        "        return None\n",
        "    img_byte_arr = io.BytesIO()\n",
        "    image.save(img_byte_arr, format='PNG') # Save as PNG to preserve transparency\n",
        "    img_byte_arr.seek(0) # Seek to the beginning of the BytesIO object\n",
        "    return img_byte_arr.getvalue() # Return the byte content\n",
        "\n",
        "\n",
        "# Create the Gradio Blocks interface\n",
        "with gr.Blocks(title=\"AI Background Remover with Sharpening and Download\") as iface:\n",
        "    gr.Markdown(\"# AI Background Remover with Sharpening and Download\")\n",
        "    gr.Markdown(\"Upload an image, automatically remove the background, optionally sharpen, and download the result.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            input_image = gr.Image(type=\"pil\", label=\"Upload Image\")\n",
        "            model_dropdown = gr.Dropdown(choices=model_options, value='u2net', label=\"Select AI Model\")\n",
        "            sharpen_checkbox = gr.Checkbox(label=\"Apply Sharpening\", value=False)\n",
        "            remove_button = gr.Button(\"Remove Background\")\n",
        "\n",
        "        with gr.Column():\n",
        "            processed_image = gr.Image(type=\"pil\", label=\"Processed Image with Background Removed\", interactive=False)\n",
        "            download_button = gr.Button(\"Download Processed Image\")\n",
        "            download_file = gr.File(label=\"Download File\")\n",
        "\n",
        "\n",
        "    # Define the workflow\n",
        "    remove_button.click(\n",
        "        fn=remove_background_gradio,\n",
        "        inputs=[input_image, model_dropdown, sharpen_checkbox],\n",
        "        outputs=[processed_image]\n",
        "    )\n",
        "\n",
        "    # Link the download button to the function that prepares the image for download\n",
        "    download_button.click(\n",
        "        fn=prepare_image_for_download,\n",
        "        inputs=[processed_image],\n",
        "        outputs=[download_file]\n",
        "    )\n",
        "\n",
        "\n",
        "# Launch the Gradio app\n",
        "iface.launch(share=True)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://40ab12b0f6f737e72c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://40ab12b0f6f737e72c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}